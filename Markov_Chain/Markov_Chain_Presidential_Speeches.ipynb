{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Markov Chain for speech genaration.\n",
    "\n",
    "Vishnupriya Venkateswaran\n",
    "04/22/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd \n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Chief', 'Justice', 'Roberts', ',', 'President', 'Carter', ',', 'President', 'Clinton', ',', 'President', 'Bush', ',', 'President', 'Obama', ',', 'fellow', 'Americans', ',', 'and', 'people', 'of', 'the', 'world', ':', 'Thank', 'you', '.'], ['We', ',', 'the', 'citizens', 'of', 'America', ',', 'are', 'now', 'joined', 'in', 'a', 'great', 'national', 'effort', 'to', 'rebuild', 'our', 'country', 'and', 'restore', 'its', 'promise', 'for', 'all', 'of', 'our', 'people', '.'], ['Together', ',', 'we', 'will', 'determine', 'the', 'course', 'of', 'America', 'and', 'the', 'world', 'for', 'many', ',', 'many', 'years', 'to', 'come', '.'], ['We', 'will', 'face', 'challenges', ',', 'we', 'will', 'confront', 'hardships', ',', 'but', 'we', 'will', 'get', 'the', 'job', 'done', '.'], ['Every', '4', 'years', ',', 'we', 'gather', 'on', 'these', 'steps', 'to', 'carry', 'out', 'the', 'orderly', 'and', 'peaceful', 'transfer', 'of', 'power', ',', 'and', 'we', 'are', 'grateful', 'to', 'President', 'Obama', 'and', 'First', 'Lady', 'Michelle', 'Obama', 'for', 'their', 'gracious', 'aid', 'throughout', 'this', 'transition', '.'], ['They', 'have', 'been', 'magnificent', '.'], ['Thank', 'you', '.'], ['Today', \"'s\", 'ceremony', ',', 'however', ',', 'has', 'very', 'special', 'meaning', '.'], ['Because', 'today', 'we', 'are', 'not', 'merely', 'transferring', 'power', 'from', 'one', 'administration', 'to', 'another', 'or', 'from', 'one', 'party', 'to', 'another', ',', 'but', 'we', 'are', 'transferring', 'power', 'from', 'Washington', ',', 'DC', ',', 'and', 'giving', 'it', 'back', 'to', 'you', ',', 'the', 'people', '.'], ['For', 'too', 'long', ',', 'a', 'small', 'group', 'in', 'our', 'Nation', \"'s\", 'Capital', 'has', 'reaped', 'the', 'rewards', 'of', 'Government', 'while', 'the', 'people', 'have', 'borne', 'the', 'cost', '.'], ['Washington', 'flourished', ',', 'but', 'the', 'people', 'did', 'not', 'share', 'in', 'its', 'wealth', '.'], ['Politicians', 'prospered', ',', 'but', 'the', 'jobs', 'left', ',', 'and', 'the', 'factories', 'closed', '.'], ['The', 'establishment', 'protected', 'itself', ',', 'but', 'not', 'the', 'citizens', 'of', 'our', 'country', '.'], ['Their', 'victories', 'have', 'not', 'been', 'your', 'victories', ';', 'their', 'triumphs', 'have', 'not', 'been', 'your', 'triumphs', ';', 'and', 'while', 'they', 'celebrated', 'in', 'our', 'Nation', \"'s\", 'Capital', ',', 'there', 'was', 'little', 'to', 'celebrate', 'for', 'struggling', 'families', 'all', 'across', 'our', 'land', '.'], ['That', 'all', 'changes', ',', 'starting', 'right', 'here', 'and', 'right', 'now', ',', 'because', 'this', 'moment', 'is', 'your', 'moment', ':', 'It', 'belongs', 'to', 'you', '.'], ['It', 'belongs', 'to', 'everyone', 'gathered', 'here', 'today', 'and', 'everyone', 'watching', 'all', 'across', 'America', '.'], ['This', 'is', 'your', 'day', '.'], ['This', 'is', 'your', 'celebration', '.'], ['And', 'this', ',', 'the', 'United', 'States', 'of', 'America', ',', 'is', 'your', 'country', '.'], ['What', 'truly', 'matters', 'is', 'not', 'which', 'party', 'controls', 'our', 'Government', ',', 'but', 'whether', 'our', 'Government', 'is', 'controlled', 'by', 'the', 'people', '.'], ['January', '20', ',', '2017', ',', 'will', 'be', 'remembered', 'as', 'the', 'day', 'the', 'people', 'became', 'the', 'rulers', 'of', 'this', 'Nation', 'again', '.'], ['The', 'forgotten', 'men', 'and', 'women', 'of', 'our', 'country', 'will', 'be', 'forgotten', 'no', 'longer', '.'], ['Everyone', 'is', 'listening', 'to', 'you', 'now', '.'], ['You', 'came', 'by', 'the', 'tens', 'of', 'millions', 'to', 'become', 'part', 'of', 'a', 'historic', 'movement', 'the', 'likes', 'of', 'which', 'the', 'world', 'has', 'never', 'seen', 'before', '.'], ['At', 'the', 'center', 'of', 'this', 'movement', 'is', 'a', 'crucial', 'conviction', ':', 'that', 'a', 'nation', 'exists', 'to', 'serve', 'its', 'citizens', '.'], ['Americans', 'want', 'great', 'schools', 'for', 'their', 'children', ',', 'safe', 'neighborhoods', 'for', 'their', 'families', ',', 'and', 'good', 'jobs', 'for', 'themselves', '.'], ['These', 'are', 'just', 'and', 'reasonable', 'demands', 'of', 'righteous', 'people', 'and', 'a', 'righteous', 'public', '.'], ['But', 'for', 'too', 'many', 'of', 'our', 'citizens', ',', 'a', 'different', 'reality', 'exists', ':', 'Mothers', 'and', 'children', 'trapped', 'in', 'poverty', 'in', 'our', 'inner', 'cities', ';', 'rusted-out', 'factories', 'scattered', 'like', 'tombstones', 'across', 'the', 'landscape', 'of', 'our', 'Nation', ';', 'an', 'education', 'system', ',', 'flush', 'with', 'cash', ',', 'but', 'which', 'leaves', 'our', 'young', 'and', 'beautiful', 'students', 'deprived', 'of', 'all', 'knowledge', ';', 'and', 'the', 'crime', 'and', 'the', 'gangs', 'and', 'the', 'drugs', 'that', 'have', 'stolen', 'too', 'many', 'lives', 'and', 'robbed', 'our', 'country', 'of', 'so', 'much', 'unrealized', 'potential', '.'], ['This', 'American', 'carnage', 'stops', 'right', 'here', 'and', 'stops', 'right', 'now', '.'], ['We', 'are', 'one', 'Nation', ',', 'and', 'their', 'pain', 'is', 'our', 'pain', ',', 'their', 'dreams', 'are', 'our', 'dreams', ',', 'and', 'their', 'success', 'will', 'be', 'our', 'success', '.'], ['We', 'share', 'one', 'heart', ',', 'one', 'home', ',', 'and', 'one', 'glorious', 'destiny', '.'], ['The', 'oath', 'of', 'office', 'I', 'take', 'today', 'is', 'an', 'oath', 'of', 'allegiance', 'to', 'all', 'Americans', '.'], ['For', 'many', 'decades', ',', 'we', \"'ve\", 'enriched', 'foreign', 'industry', 'at', 'the', 'expense', 'of', 'American', 'industry', ',', 'subsidized', 'the', 'armies', 'of', 'other', 'countries', 'while', 'allowing', 'for', 'the', 'very', 'sad', 'depletion', 'of', 'our', 'military', '.'], ['We', \"'ve\", 'defended', 'other', 'nations', \"'\", 'borders', 'while', 'refusing', 'to', 'defend', 'our', 'own', 'and', 'spent', 'trillions', 'and', 'trillions', 'of', 'dollars', 'overseas', 'while', 'America', \"'s\", 'infrastructure', 'has', 'fallen', 'into', 'disrepair', 'and', 'decay', '.'], ['We', \"'ve\", 'made', 'other', 'countries', 'rich', 'while', 'the', 'wealth', ',', 'strength', ',', 'and', 'confidence', 'of', 'our', 'country', 'has', 'dissipated', 'over', 'the', 'horizon', '.'], ['One', 'by', 'one', ',', 'the', 'factories', 'shuttered', 'and', 'left', 'our', 'shores', ',', 'with', 'not', 'even', 'a', 'thought', 'about', 'the', 'millions', 'and', 'millions', 'of', 'American', 'workers', 'that', 'were', 'left', 'behind', '.'], ['The', 'wealth', 'of', 'our', 'middle', 'class', 'has', 'been', 'ripped', 'from', 'their', 'homes', 'and', 'then', 'redistributed', 'all', 'across', 'the', 'world', '.'], ['But', 'that', 'is', 'the', 'past', '.'], ['And', 'now', 'we', 'are', 'looking', 'only', 'to', 'the', 'future', '.'], ['We', ',', 'assembled', 'here', 'today', ',', 'are', 'issuing', 'a', 'new', 'decree', 'to', 'be', 'heard', 'in', 'every', 'city', ',', 'in', 'every', 'foreign', 'capital', ',', 'and', 'in', 'every', 'hall', 'of', 'power', '.'], ['From', 'this', 'day', 'forward', ',', 'a', 'new', 'vision', 'will', 'govern', 'our', 'land', '.'], ['From', 'this', 'this', 'day', 'forward', ',', 'it', \"'s\", 'going', 'to', 'be', 'only', 'America', 'first', '.'], ['America', 'first', '.'], ['Every', 'decision', 'on', 'trade', ',', 'on', 'taxes', ',', 'on', 'immigration', ',', 'on', 'foreign', 'affairs', ',', 'will', 'be', 'made', 'to', 'benefit', 'American', 'workers', 'and', 'American', 'families', '.'], ['We', 'must', 'protect', 'our', 'borders', 'from', 'the', 'ravages', 'of', 'other', 'countries', 'making', 'our', 'products', ',', 'stealing', 'our', 'companies', ',', 'and', 'destroying', 'our', 'jobs', '.'], ['Protection', 'will', 'lead', 'to', 'great', 'prosperity', 'and', 'strength', '.'], ['I', 'will', 'fight', 'for', 'you', 'with', 'every', 'breath', 'in', 'my', 'body', ',', 'and', 'I', 'will', 'never', ',', 'ever', 'let', 'you', 'down', '.'], ['America', 'will', 'start', 'winning', 'again', ',', 'winning', 'like', 'never', 'before', '.'], ['We', 'will', 'bring', 'back', 'our', 'jobs', '.'], ['We', 'will', 'bring', 'back', 'our', 'borders', '.'], ['We', 'will', 'bring', 'back', 'our', 'wealth', '.'], ['And', 'we', 'will', 'bring', 'back', 'our', 'dreams', '.'], ['We', 'will', 'build', 'new', 'roads', 'and', 'highways', 'and', 'bridges', 'and', 'airports', 'and', 'tunnels', 'and', 'railways', 'all', 'across', 'our', 'wonderful', 'Nation', '.'], ['We', 'will', 'get', 'our', 'people', 'off', 'of', 'welfare', 'and', 'back', 'to', 'work', ',', 'rebuilding', 'our', 'country', 'with', 'American', 'hands', 'and', 'American', 'labor', '.'], ['We', 'will', 'follow', 'two', 'simple', 'rules', ':', 'Buy', 'American', 'and', 'hire', 'American', '.'], ['We', 'will', 'seek', 'friendship', 'and', 'good', 'will', 'with', 'the', 'nations', 'of', 'the', 'world', ',', 'but', 'we', 'do', 'so', 'with', 'the', 'understanding', 'that', 'it', 'is', 'the', 'right', 'of', 'all', 'nations', 'to', 'put', 'their', 'own', 'interests', 'first', '.'], ['We', 'do', 'not', 'seek', 'to', 'impose', 'our', 'way', 'of', 'life', 'on', 'anyone', ',', 'but', 'rather', 'to', 'let', 'it', 'shine', 'as', 'an', 'example—we', 'will', 'shine—for', 'everyone', 'to', 'follow', '.'], ['We', 'will', 'reinforce', 'old', 'alliances', 'and', 'form', 'new', 'ones', 'and', 'unite', 'the', 'civilized', 'world', 'against', 'radical', 'Islamic', 'terrorism', ',', 'which', 'we', 'will', 'eradicate', 'completely', 'from', 'the', 'face', 'of', 'the', 'Earth', '.'], ['At', 'the', 'bedrock', 'of', 'our', 'politics', 'will', 'be', 'a', 'total', 'allegiance', 'to', 'the', 'United', 'States', 'of', 'America', ',', 'and', 'through', 'our', 'loyalty', 'to', 'our', 'country', ',', 'we', 'will', 'rediscover', 'our', 'loyalty', 'to', 'each', 'other', '.'], ['When', 'you', 'open', 'your', 'heart', 'to', 'patriotism', ',', 'there', 'is', 'no', 'room', 'for', 'prejudice', '.'], ['The', 'Bible', 'tells', 'us', ',', '``', 'How', 'good', 'and', 'pleasant', 'it', 'is', 'when', 'God', \"'s\", 'people', 'live', 'together', 'in', 'unity', '.', \"''\"], ['We', 'must', 'speak', 'our', 'minds', 'openly', ',', 'debate', 'our', 'disagreements', 'honestly', ',', 'but', 'always', 'pursue', 'solidarity', '.'], ['When', 'America', 'is', 'united', ',', 'America', 'is', 'totally', 'unstoppable', '.'], ['There', 'should', 'be', 'no', 'fear', ':', 'We', 'are', 'protected', ',', 'and', 'we', 'will', 'always', 'be', 'protected', '.'], ['We', 'will', 'be', 'protected', 'by', 'the', 'great', 'men', 'and', 'women', 'of', 'our', 'military', 'and', 'law', 'enforcement', ',', 'and', 'most', 'importantly', ',', 'we', 'will', 'be', 'protected', 'by', 'God', '.'], ['Finally', ',', 'we', 'must', 'think', 'big', 'and', 'dream', 'even', 'bigger', '.'], ['In', 'America', ',', 'we', 'understand', 'that', 'a', 'nation', 'is', 'only', 'living', 'as', 'long', 'as', 'it', 'is', 'striving', '.'], ['We', 'will', 'no', 'longer', 'accept', 'politicians', 'who', 'are', 'all', 'talk', 'and', 'no', 'action', ',', 'constantly', 'complaining', ',', 'but', 'never', 'doing', 'anything', 'about', 'it', '.'], ['The', 'time', 'for', 'empty', 'talk', 'is', 'over', '.'], ['Now', 'arrives', 'the', 'hour', 'of', 'action', '.'], ['Do', 'not', 'allow', 'anyone', 'to', 'tell', 'you', 'that', 'it', 'can', 'not', 'be', 'done', '.'], ['No', 'challenge', 'can', 'match', 'the', 'heart', 'and', 'fight', 'and', 'spirit', 'of', 'America', '.'], ['We', 'will', 'not', 'fail', '.'], ['Our', 'country', 'will', 'thrive', 'and', 'prosper', 'again', '.'], ['We', 'stand', 'at', 'the', 'birth', 'of', 'a', 'new', 'millennium', ',', 'ready', 'to', 'unlock', 'the', 'mysteries', 'of', 'space', ',', 'to', 'free', 'the', 'Earth', 'from', 'the', 'miseries', 'of', 'disease', ',', 'and', 'to', 'harness', 'the', 'energies', ',', 'industries', ',', 'and', 'technologies', 'of', 'tomorrow', '.'], ['A', 'new', 'national', 'pride', 'will', 'stir', 'our', 'souls', ',', 'lift', 'our', 'sights', ',', 'and', 'heal', 'our', 'divisions', '.'], ['It', \"'s\", 'time', 'to', 'remember', 'that', 'old', 'wisdom', 'our', 'soldiers', 'will', 'never', 'forget', ':', 'that', 'whether', 'we', 'are', 'Black', 'or', 'Brown', 'or', 'White', ',', 'we', 'all', 'bleed', 'the', 'same', 'red', 'blood', 'of', 'patriots', ',', 'we', 'all', 'enjoy', 'the', 'same', 'glorious', 'freedoms', ',', 'and', 'we', 'all', 'salute', 'the', 'same', 'great', 'American', 'flag', '.'], ['And', 'whether', 'a', 'child', 'is', 'born', 'in', 'the', 'urban', 'sprawl', 'of', 'Detroit', 'or', 'the', 'windswept', 'plains', 'of', 'Nebraska', ',', 'they', 'look', 'up', 'at', 'the', 'same', 'night', 'sky', ',', 'they', 'fill', 'their', 'heart', 'with', 'the', 'same', 'dreams', ',', 'and', 'they', 'are', 'infused', 'with', 'the', 'breath', 'of', 'life', 'by', 'the', 'same', 'almighty', 'Creator', '.'], ['So', 'to', 'all', 'Americans', 'in', 'every', 'city', 'near', 'and', 'far', ',', 'small', 'and', 'large', ',', 'from', 'mountain', 'to', 'mountain', ',', 'from', 'ocean', 'to', 'ocean', ',', 'hear', 'these', 'words', ':', 'You', 'will', 'never', 'be', 'ignored', 'again', '.'], ['Your', 'voice', ',', 'your', 'hopes', ',', 'and', 'your', 'dreams', 'will', 'define', 'our', 'American', 'destiny', '.'], ['And', 'your', 'courage', 'and', 'goodness', 'and', 'love', 'will', 'forever', 'guide', 'us', 'along', 'the', 'way', '.'], ['Together', ',', 'we', 'will', 'make', 'America', 'strong', 'again', '.'], ['We', 'will', 'make', 'America', 'wealthy', 'again', '.'], ['We', 'will', 'make', 'America', 'proud', 'again', '.'], ['We', 'will', 'make', 'America', 'safe', 'again', '.'], ['And', ',', 'yes', ',', 'together', ',', 'we', 'will', 'make', 'America', 'great', 'again', '.'], ['Thank', 'you', '.'], ['God', 'bless', 'you', ',', 'and', 'God', 'bless', 'America', '.'], ['Thank', 'you', '.'], ['God', 'bless', 'America', '.']]\n"
     ]
    }
   ],
   "source": [
    "#Read Input file\n",
    "\n",
    "file = open('data/speech_11.txt', 'r')\n",
    "speech = file.read()\n",
    "sentences = sent_tokenize(speech)\n",
    "\n",
    "#speech = speech.split()\n",
    "#sentences = [y for x in sentences for y in x]\n",
    "#print(sentences)\n",
    "reference = []\n",
    "for s in sentences:\n",
    "    reference.append(word_tokenize(s))\n",
    "    \n",
    "print(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = \"America wealthy again. And, yes, together, we all bleed the energies, industries, and highways and we understand that a crucial conviction: that a righteous people of this movement the heart and your victories; their homes and left our loyalty to unlock the windswept plains of dollars overseas while they look\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['America wealthy again.', 'And, yes, together, we all bleed the energies, industries, and highways and we understand that a crucial conviction: that a righteous people of this movement the heart and your victories; their homes and left our loyalty to unlock the windswept plains of dollars overseas while they look']\n"
     ]
    }
   ],
   "source": [
    "candidate_sentences = sent_tokenize(candidate)\n",
    "print(candidate_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['America', 'wealthy', 'again', '.'], ['And', ',', 'yes', ',', 'together', ',', 'we', 'all', 'bleed', 'the', 'energies', ',', 'industries', ',', 'and', 'highways', 'and', 'we', 'understand', 'that', 'a', 'crucial', 'conviction', ':', 'that', 'a', 'righteous', 'people', 'of', 'this', 'movement', 'the', 'heart', 'and', 'your', 'victories', ';', 'their', 'homes', 'and', 'left', 'our', 'loyalty', 'to', 'unlock', 'the', 'windswept', 'plains', 'of', 'dollars', 'overseas', 'while', 'they', 'look']]\n"
     ]
    }
   ],
   "source": [
    "candidate = []\n",
    "for s in candidate_sentences:\n",
    "    candidate.append(word_tokenize(s))\n",
    "    \n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6544988799841042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = sentence_bleu(reference, candidate[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function makes pairs of words\n",
    "def makePairs(arr):\n",
    "    pairs = []\n",
    "    for i in range(len(arr)):\n",
    "        if i < len(arr)-1: \n",
    "            temp = (arr[i], arr[i+1])\n",
    "            pairs.append(temp)\n",
    "    return pairs\n",
    "\n",
    "#This function will generate a word randomly using conditional distribution\n",
    "def generate(cfd, word = 'the', num = 50):\n",
    "    for i in range(num):\n",
    "        arr = []                                      # make an array with the words shown by proper count\n",
    "        for j in cfd[word]:\n",
    "            for k in range(cfd[word][j]):\n",
    "                arr.append(j)\n",
    "        \n",
    "        print(word, end=' ')\n",
    "        word = arr[int((len(arr))*random.random())]     # choose the word randomly from the conditional distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-52936a9a627e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakePairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConditionalFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-6668dbf7d4a1>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(cfd, word, num)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m# choose the word randomly from the conditional distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#The resulting speech is genarated \n",
    "pairs = makePairs(speech)\n",
    "cfd = nltk.ConditionalFreqDist(pairs)\n",
    "generate(cfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the course of our borders. We will eradicate completely from one party controls our wonderful Nation. We must think big and trillions of America, are now joined in the world. But for empty talk and peaceful transfer of the heart with not fail. Our country with the drugs that it "
     ]
    }
   ],
   "source": [
    "# This method will genarate text with a provided word. \n",
    "\n",
    "def makeText(fileName, word = 'the', num = 50):\n",
    "    file = open(fileName, 'r')\n",
    "    string = file.read()\n",
    "    stringArr = string.split()\n",
    "    \n",
    "    pairs = makePairs(stringArr)\n",
    "    model = nltk.ConditionalFreqDist(pairs)\n",
    "    generate(model, word, num)\n",
    "\n",
    "        \n",
    "makeText('data/speech_11.txt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "America wealthy again. And, yes, together, we all bleed the energies, industries, and highways and we understand that a crucial conviction: that a righteous people of this movement the heart and your victories; their homes and left our loyalty to unlock the windswept plains of dollars overseas while they look "
     ]
    }
   ],
   "source": [
    "makeText('data/speech_11.txt', 'America') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great men and confidence of this transition. They have not been your heart to remember that a great men and unite the United States of office I will bring back our minds openly, debate our military. We've made to be no action, constantly complaining, but we will rediscover our land. "
     ]
    }
   ],
   "source": [
    "makeText('data/speech_11.txt','great') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Choice of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cities; rusted-out factories scattered like never before. We will thrive and God bless you, and peaceful transfer of our dreams, and their triumphs have stolen too long, a child is united, America first. America proud again. We will make America safe neighborhoods for many, many years to celebrate for all across our soldiers will make America great men and the same night sky, they look up at the heart with the drugs that whether our dreams.\n",
      "We will govern our country and love will never doing anything about it. The time for struggling families all Americans in every breath of our\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "speeches = open(\"data/speech_11.txt\", \"r\").read()\n",
    "speeches = ''.join([i for i in speeches if not i.isdigit()]).replace(\"\\n\\n\", \" \").split(' ')\n",
    "# This process the list of speeches. Double line breaks separate speeches, so they are removed.\n",
    "# Splitting along spaces creates a list of all words.\n",
    "\n",
    "index = 1\n",
    "chain = {}\n",
    "count = 100 # Desired word count of output\n",
    "\n",
    "# This loop creates a dicitonary called \"chain\". Each key is a word, and the value of each key\n",
    "# is an array of the words that immediately followed it.\n",
    "for word in speeches[index:]: \n",
    "    key = speeches[index - 1]\n",
    "    if key in chain:\n",
    "        chain[key].append(word)\n",
    "    else:\n",
    "        chain[key] = [word]\n",
    "    index += 1\n",
    "\n",
    "word1 = random.choice(list(chain.keys())) #random first word\n",
    "message = word1.capitalize()\n",
    "\n",
    "# Picks the next word over and over until word count achieved\n",
    "while len(message.split(' ')) < count:\n",
    "    word2 = random.choice(chain[word1])\n",
    "    word1 = word2\n",
    "    message += ' ' + word2\n",
    "\n",
    "# creates new file with output and prints it to the terminal\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    file.write(message)\n",
    "output = open(\"output.txt\",\"r\")\n",
    "print(output.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = []\n",
    "candidate = ['this', 'is', 'a', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
